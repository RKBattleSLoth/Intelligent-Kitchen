# Server Configuration
NODE_ENV=development
PORT=3001

# Database Configuration
DATABASE_URL=postgresql://kitchen_user:kitchen_password@localhost:5432/intelligent_kitchen
DB_HOST=localhost
DB_PORT=5432
DB_NAME=intelligent_kitchen
DB_USER=kitchen_user
DB_PASSWORD=kitchen_password

# Redis Configuration
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRES_IN=7d

# Frontend URL
FRONTEND_URL=http://localhost:3000

# External API Keys (for production)
SPOONACULAR_API_KEY=your-spoonacular-api-key
GOOGLE_CLOUD_API_KEY=your-google-cloud-api-key

# File Upload Configuration
MAX_FILE_SIZE=10485760
UPLOAD_PATH=uploads/

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
# ===========================================
# OpenRouter AI Configuration
# ===========================================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key

# Model Configuration (3-Tier System)
# Small Model (128K context): Fast conversational queries, simple tasks
# Recommended: google/gemma-2-9b-it, anthropic/claude-3-haiku, meta-llama/llama-3-8b-instruct
OPENROUTER_MODEL_SMALL=google/gemma-2-9b-it

# Medium Model (200K context): Logic, processing, tool execution
# Recommended: anthropic/claude-3.5-sonnet, google/gemini-1.5-flash, openai/gpt-4o-mini
OPENROUTER_MODEL_MEDIUM=anthropic/claude-3.5-sonnet

# Large Model (1M+ context): Data-heavy operations, vision, complex analysis
# Recommended: google/gemini-1.5-pro, anthropic/claude-3-opus, openai/gpt-4o
OPENROUTER_MODEL_LARGE=google/gemini-1.5-pro

# Application Metadata
OPENROUTER_APP_TITLE=Intelligent Kitchen AI
APP_URL=http://localhost:3000

# ===========================================
# AI Service Configuration
# ===========================================
# Enable response caching to reduce costs (30-40% savings typical)
AI_ENABLE_CACHING=true

# Cache TTL in seconds (3600 = 1 hour)
AI_CACHE_TTL=3600

# Maximum retry attempts for failed AI requests
AI_MAX_RETRIES=3

# Request timeout in milliseconds
AI_TIMEOUT=30000

# Enable streaming responses (for real-time chat)
AI_ENABLE_STREAMING=true

# ===========================================
# AI Rate Limiting (per user)
# ===========================================
# Maximum AI requests per minute per user
AI_RATE_LIMIT_REQUESTS_PER_MINUTE=20

# Maximum tokens per day per user (helps control costs)
AI_RATE_LIMIT_TOKENS_PER_DAY=1000000

# ===========================================
# AI Cost Management
# ===========================================
# Enable cost monitoring and alerts
AI_ENABLE_COST_MONITORING=true

# Alert when daily cost exceeds this amount (USD)
AI_COST_ALERT_THRESHOLD=100

# Maximum cost per user per month (USD)
AI_MAX_COST_PER_USER_MONTHLY=50
